An action recognizer framework built with Python, Mediapipe, Tensorflow, and OpenCV. Takes the user's joint positions and predicts the user's actions based on training data.

## How it works
Using the Mediapipe and OpenCV packages, the user can gather training data by recording their own movements. Then, by training a custom Keras LSTM, the user can then train a machine learning model to recognize their motions and attribute them to a labelled class.
